sub("[^A-Za-z]+", "S", "teste 0 jdias cço pão")
library(qdap)
mgsub(a, b, v1)
install.packages("qdap")
v1 <- c('I got 95% in maths & 80% in science',
'He got 90% in maths & 70% in science')
b <- c('\\%', '\\&')
mgsub(a, b, v1)
library(qdap)
mgsub(a, b, v1)
a <- c('%', '&')
library(qdap)
mgsub(a, b, v1)
de <- c('ç','ã','à','á','â','é','ê','è','í','ì','ó','ò','ô','õ','ú','ù','ü')
para <= c('c','a','a','a','a','e','e','e','i','i','o','o','o','o','u','u','u')
p <= c('c','a','a','a','a','e','e','e','i','i','o','o','o','o','u','u','u')
para <- c('c','a','a','a','a','e','e','e','i','i','o','o','o','o','u','u','u')
v1 <- c('Você é o único daí, vamos vê!',
+         'Começo falando de comemoração')
v1 <- c('Você é o único daí, vamos vê!',
'Começo falando de comemoração')
library(qdap)
mgsub(de, para, v1)
library("qdap")
mgsub(de, para, v1)
gsub("[^[:alnum:][:blank:]+?&/\\-]", "", v1)
str_replace_all(v1,"[[:punct:]\\\s]+","_")
(result <- sapply(v1, stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE))
sapply(v1, stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE)
sapply("história", stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE)
sapply("histõria", stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE)
sapply("histãria", stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE)
sapply("histãrico", stringi::stri_replace_all_fixed, de, para, vectorize_all = FALSE, USE.NAMES = FALSE)
require(XML)
require(tm)
require(wordcloud)
require(RColorBrewer)
u = "http://cran.r-project.org/web/packages/available_packages_by_date.html"
t = readHTMLTable(u)[[1]]
ap.corpus <- Corpus(DataframeSource(data.frame(as.character(t[,3]))))
ap.corpus <- tm_map(ap.corpus, removePunctuation)
ap.corpus <- tm_map(ap.corpus, content_transformer(tolower))
ap.corpus <- tm_map(ap.corpus, function(x) removeWords(x, stopwords("english")))
ap.corpus <- Corpus(VectorSource(ap.corpus))
ap.tdm <- TermDocumentMatrix(ap.corpus)
ap.m <- as.matrix(ap.tdm)
ap.v <- sort(rowSums(ap.m),decreasing=TRUE)
ap.d <- data.frame(word = names(ap.v),freq=ap.v)
table(ap.d$freq)
pal2 <- brewer.pal(8,"Dark2")
png("wordcloud_packages.png", width=1280,height=800)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,
max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
dev.off()
pal2 <- brewer.pal(8,"Dark2")
png("wordcloud_packages.png", width=1280,height=800)
wordcloud(theCorpus[idx],ap.d$freq, scale=c(8,.2),min.freq=3,
max.words=maxWords, random.order=FALSE, rot.per=.15, colors=pal2)
pal2 <- brewer.pal(8,"Dark2")
png("wordcloud_packages.png", width=1280,height=800)
wordcloud(ap.d$word,ap.d$freq, scale=c(8,.2),min.freq=3,
max.words=Inf, random.order=FALSE, rot.per=.15, colors=pal2)
install.packages("devtools")
datasetBugId <- read.csv(file="C:/Users/Charles/Desktop/Mestrado USP/Dissertação e Projeto/Experimentos/Experimentos - Discovering Bug Patterns In JS/DataSet/dataset_bugid.csv", header=TRUE, sep=",")
db <- datasetBugId[10:669]
View(datasetBugId)
library("dbscan")
res.db <- dbscan::dbscan(db, 0.30, 5)
res.db$cluster
clustersDBScan <- res.db$cluster
teste <- datasetBugId[9:10]
View(teste)
datasetBugId$Cluster <- clustersDBScan
View(datasetBugId)
library(data.table)
dt <- data.table(datasetBugId)
library(data.table)
dt <- data.table(datasetBugId)
dt[, sum(ID), by = Cluster]
result <- dt[, sum(ID), by = Cluster]
View(result)
result <- result[order(Cluster)]
View(result)
result <- result[order(V1)]
result <- result[order(-V1)]
result <- dt[, sum(BugFixingCommit), by = Cluster]
datasetBugId$Qtd = 1;
result <- dt[, sum(datasetBugId), by = Cluster]
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- result[order(-V1)]
View(result)
View(result)
View(db)
db <- datasetBugId[11:669]
library("dbscan")
res.db <- dbscan::dbscan(db, 0.30, 5)
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
library(data.table)
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
View(result)
result <- result[order(-V1)]
View(datasetBugId)
db <- datasetBugId[10:669]
db <- datasetBugId[10:669]
res.db <- dbscan::dbscan(db, 0.30, 5)
# Obter os clusters
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
library(data.table)
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
#Ordenar pela quantidade
result <- result[order(-V1)]
View(dt)
dt[, 669]
dt[, 670]
cat("\014")
dt[, 670]
dt == "Class"
dt == "METHOD.METHOD_CALL.INSERTED.global.exec"
head(db)
h <- head(db)
View(h)
db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1
tes <- db[db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1]
tes <- db[:db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1]
tes <- db[, db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1]
tes <- db[which(db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1)]
tes <- db[ which(db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1), ]
View(tes)
rowsByAttr <- c("METHOD.METHOD_CALL.INSERTED.global.reduceRight", db[ which(db$METHOD.METHOD_CALL.INSERTED.global.reduceRight == 1), ])
?dbscan
??optics
??#kmeans
datasetBugId <- read.csv(file="C:/Users/Charles/Desktop/Mestrado USP/Dissertação e Projeto/Experimentos/Experimentos - Discovering Bug Patterns In JS/DataSet/dataset_bugid.csv", header=TRUE, sep=",")
#====
data("multishapes", package = "factoextra")
db <- datasetBugId[10:669]
library("dbscan")
res.db <- dbscan::dbscan(db, 0.30, 5)
# Obter os clusters
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
?dbscan
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
library(data.table)
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
result <- result[order(-V1)]
View(result)
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
colunas[!colunas %in% metadados]
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
teste_result <- teste[teste$valor_coluna == 1,]
teste_result <- teste
teste_result_final <- teste_result[teste_result$Cluster != 0, ]
library(dplyr)
teste_result_final <- teste_result_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
teste_result_final <- teste_result_final[order(-teste_result_final$V1),]
teste_result_final <- teste_result_final[teste_result_final$Cluster != 0, ]
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
colunas[!colunas %in% metadados]
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
install.packages("tidyr")
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
teste_result <- teste[teste$valor_coluna == 1,]
teste_result <- teste
teste_result_final <- teste_result[teste_result$Cluster != 0, ]
library(dplyr)
teste_result_final <- teste_result_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
teste_result_final <- teste_result_final[order(-teste_result_final$V1),]
teste_result_final <- teste_result_final[teste_result_final$Cluster != 0, ]
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
install.packages("rlang")
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
library(rlang)
library("rlang")
library("tidyr")
library("rlang")
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
res.db <- dbscan::dbscan(db, eps=0.30, minPts = 5, weights=0.2)
res.db <- dbscan::dbscan(db, eps=0.30, minPts = 5, weights=2)
install.packages('tidyr', clean = TRUE)
install.packages('tidyr', dependencies = TRUE)
install.packages('rlang', dependencies = TRUE)
library("tidyr")
library("rlang")
library("dbscan")
datasetBugId <- read.csv(file="C:/Users/Charles/Desktop/Mestrado USP/Dissertação e Projeto/Experimentos/Experimentos - Discovering Bug Patterns In JS/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
data("multishapes", package = "factoextra")
db <- datasetBugId[10:632]
library("dbscan")
res.db <- dbscan::dbscan(db, eps=0.30, minPts = 5)
# Obter os clusters
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
library("rlang")
install.packages('tidyr', dependencies = TRUE)
library("rlang")
install.packages('rlang', dependencies = TRUE)
library("rlang")
version
if(!require(installr)) {
install.packages("installr"); require(installr)}
updateR()
updateR()
version
version
install.packages("microbenchmark")
install.packages("microbenchmark")
install.packages("microbenchmarkCore")
version
library(microbenchmark)
install.packages("microbenchmark", dependencies = TRUE)
library(microbenchmark)
library("rlang")
library(rlang)
install.packages("rlang")
library(microbenchmark)
library("ggplot2")
library("ggplot")
install.packages("rlang")
library(microbenchmark)
install.packages("rlang")
install.packages("rlang")
library(microbenchmark)
library(microbenchmark)
install.packages("microbenchmarkCore")
setwd("G:/Mestrado/Meus experimentos/Meu GitHub/ExperimentsPapers/DescobrindoPadroesdeBugJS/CodeR/evaluation")
setwd("G:/Mestrado/Meus experimentos/Meu GitHub/ExperimentsPapers/DescobrindoPadroesdeBugJS/CodeR/evaluation")
setwd("G:/Mestrado/Meus experimentos/Meu GitHub/ExperimentsPapers/DescobrindoPadroesdeBugJS/CodeR/evaluation")
# ===========
# Obter todos os conjuntos básicos de mudança
# ===========
# Leitura de CSV
# CSV com todos os Reparos classificados pelos Hanan, com os seus repectivos BCTs
conjuntosBCTs <- read.csv(file="original dataset/tablecct.csv", header=TRUE, sep=";")
# Obtendo cada BCT dentro das assinaturas do conjunto de mudanças básicas de cada correção
library(stringr)
quebraBcts <- as.data.frame(str_split(conjuntosBCTs$Signature, "<br>", simplify = TRUE))
# Renomear as colunas
colnames(quebraBcts) <- c("bct1", "bct2", "bct3", "bct4")
# Atribuindo os IDs, Média de Modficações e a quantidade de BCTs da correção na matriz com os BCTs por coluna
quebraBcts$IdCCT <- conjuntosBCTs$ID
quebraBcts$Avg.Modified.Statements <- conjuntosBCTs$Avg.Modified.Statements
quebraBcts$CountBCTs <- conjuntosBCTs$BCTs
# ===========
# ===========
# Obter o dataset com o Grupo de Padrões de Defeitos
# ===========
padroesDefeitos <- read.csv(file="original dataset/tablebugpatterns.csv", header=TRUE, sep=";")
padroesDefeitos$Change.Types.Groups.List <- str_split(padroesDefeitos$Change.Types.Groups, ",")
PadroesDefeitosPorConjutoBCTs <- data.frame(IDBugPatterns=integer(),
Fault=character(),
Repair=character(),
Bct1=character(),
Bct2=character(),
Bct3=character(),
Bct4=character(),
IdCCT = integer(),
AvgModifiedStatements = integer(),
CountBCTs = integer(),
stringsAsFactors=FALSE)
idChangeType <- integer(0L)
for(i in 1:dim(padroesDefeitos)[1]) {
for (j in 1:length(padroesDefeitos[i,]$Change.Types.Groups.List[[1]])) {
idChangeType <- as.integer(padroesDefeitos[i,]$Change.Types.Groups.List[[1]][j])
PadroesDefeitosPorConjutoBCTs <-
rbind(PadroesDefeitosPorConjutoBCTs, as.data.frame(c(padroesDefeitos[i,c(1:3)],
quebraBcts[quebraBcts$IdCCT==idChangeType, ])))
}
}
# ===========
# Obter o dataset de classificações feita pelo estudo do Hanan (BUgAID)
# ===========
languageconstruct <- read.csv(file="original dataset/language_construct_database.csv",
header=TRUE, sep=";")
# ===========
# Obter o dataset que o Hanan informou ter as informações de {Reparo, Label}
# ===========
datasetLabelReparoCommit <- read.csv(file="original dataset/oracle.csv",
header=TRUE, sep=";")
# ===========
# Realizando um Join entre os três datasets
# ===========
View(datasetLabelReparoCommit)
library(dplyr)
View(languageconstruct)
View(datasetLabelReparoCommit)
names(datasetLabelReparoCommit)
names(languageconstruct)
datasetOracleCompleted <- languageconstruct %>% inner_join(datasetLabelReparoCommit, by = c("ID" = "IDCommit"))
View(PadroesDefeitosPorConjutoBCTs)
View(padroesDefeitos)
padroesDefeitos[1:3]
View(datasetOracleCompleted)
datasetOracleCompleted <- (languageconstruct %>%
inner_join(datasetLabelReparoCommit, by = c("ID" = "IDCommit"))) %>%
inner_join(padroesDefeitos[1:3], by = c("IDRepair" = "ID"))
View(datasetOracleCompleted)
names(datasetLabelReparoCommit)
names(languageconstruct)
datasetOracleCompleted <- (datasetLabelReparoCommit %>%
inner_join(languageconstruct, by = c("IDCommit" = "ID"))) %>%
inner_join(padroesDefeitos[1:3], by = c("IDRepair" = "ID"))
names(languageconstruct)[1]
languageconstruct <- read.csv(file="original dataset/language_construct_database.csv",
header=TRUE, sep=";")
names(languageconstruct)[1] <- "IDCommit"
names(languageconstruct)[1]
datasetOracleCompleted <- (languageconstruct %>%
inner_join(datasetLabelReparoCommit, by = c("IDCommit" = "IDCommit"))) %>%
inner_join(padroesDefeitos[1:3], by = c("IDRepair" = "ID"))
