source("/../helpers.R")
source("/helpers.R")
source("./../helpers.R")
source("/../helpers.R")
source("../helpers.R")
source("helpers.R")
load_helpers <- function(base_path = "../"){
source(paste0(base_path, "helpers/sql_helper.R"))
source(paste0(base_path, "helpers/string_helper.R"))
source(paste0(base_path, "helpers/corpus_helper.R"))
source(paste0(base_path, "helpers/criterios_helper.R"))
}
source("helpers.R")
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
list.of.packages <- c("readr","dplyr","tidyr","stringr","lubridate","RODBC","caret","tm","SnowballC","tidyverse","ggplot2","forcats","pROC")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
source(noquote(paste0(getwd(),"helpers.R")))
load_helpers("./")
source(noquote(paste0(getwd(),"helpers.R")))
load_helpers("./")
source(noquote(paste0(getwd(),"/helpers.R")))
source("./../helpers.R")
source("./helpers.R")
source("/helpers.R")
source("helpers.R")
load_helpers <- function(base_path = "../"){
source(paste0(base_path, "helpers/sql_helper.R"))
source(paste0(base_path, "helpers/string_helper.R"))
source(paste0(base_path, "helpers/corpus_helper.R"))
source(paste0(base_path, "helpers/criterios_helper.R"))
}
source(paste0(base_path, "helpers/sql_helper.R"))
source(paste0(base_path, "helpers/string_helper.R"))
source(paste0(base_path, "helpers/corpus_helper.R"))
source(paste0(base_path, "helpers/criterios_helper.R"))
load_helpers <- function(base_path = "./../"){
source(paste0(base_path, "helpers/sql_helper.R"))
source(paste0(base_path, "helpers/string_helper.R"))
source(paste0(base_path, "helpers/corpus_helper.R"))
source(paste0(base_path, "helpers/criterios_helper.R"))
}
load_helpers("./")
load_helpers("")
load_helpers("./")
load_helpers("./../")
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(RODBC)
library(caret)
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
load_helpers <- function(base_path = "./../"){
source(paste0(base_path, "helpers/sql_helper.R"))
source(paste0(base_path, "helpers/string_helper.R"))
source(paste0(base_path, "helpers/corpus_helper.R"))
source(paste0(base_path, "helpers/criterios_helper.R"))
}
list.of.packages <- c("readr","dplyr","tidyr","stringr","lubridate","RODBC","caret","tm","SnowballC","tidyverse","ggplot2","forcats","pROC")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(RODBC)
library(caret)
source(noquote(paste0(getwd(),"/helpers.R")))
load_helpers("./")
library(RODBC)
# "local, poc, producao
get_connection <- function(ambiente){
if(ambiente == "genoa"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:srv-db-genoa-cognitiveqm-mutant-01.database.windows.net,1433;Database=db_genoa-cognitiveqm-mutant-01;Uid=genoaadmin;Pwd=#Genoa@2017;")
}else if(ambiente == "poc"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:pocs.database.windows.net,1433;Database=poc-net;Uid=pocs;Pwd=123!@#qweQWE;")
}else if(ambiente == "vda"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:srv-db-genoa-vda-net.database.windows.net,1433;Database=db_genoa_vda_net;Uid=genoaadmin;Pwd=#Genoa@022017;")
}else if(ambiente == "icc"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:iccserver.database.windows.net,1433;Database=ICC;Uid=icc;Pwd=Esx@12345678;")
}else{
con <- odbcDriverConnect("Driver={SQL Server};Server=DESKTOP-V9ITFHP\\SQLEXPRESS;Database=POC;Integrated Security=True;Integrated Security=SSPI;")
}
con
}
close_connection <- function(con){
RODBC::odbcClose(con)
}
add_df_to_sql <- function(data, table_name, ambiente){
con <- get_connection(ambiente)
RODBC::sqlSave(con, data, table_name, rownames = FALSE, colnames = FALSE, fast = TRUE, append = TRUE)
close_connection(con)
}
execute_query <- function(query, ambiente){
con <- get_connection(ambiente)
x <- RODBC::sqlQuery(con, query, as.is = TRUE)
RODBC::odbcClose(con)
x
}
#' Clean Special Characters
#'
#' Remove all non-alphanumeric charactes
#'
#' @param x Text to be cleared
#' @param replacement a replacement for matched pattern in gsub
#' @seealso See
#'    \code{\link{clean_text}}
#'    \code{\link{clean_accent}}
#'
#' @examples
#' clean_special_characters("JoÃ£o CanÃ¡rio")
#' clean_special_characters("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_special_characters <- function(x, replacement = ""){
gsub("[^[:alnum:][:blank:]]|[[:punct:]]", replacement, x)
}
#' Clean accents
#'
#' Remove all accents from a text
#'
#' @param x Text to be cleared
#'
#' @seealso See
#'    \code{\link{clean_text}}
#'    \code{\link{clean_special_characters}}
#'    \code{\link[stringi]{stri_trans_general}}
#'
#' @examples
#' clean_accent("JoÃ£o CanÃ¡rio")
#' clean_accent("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_accent <- function(x){
stringi::stri_trans_general(str = x, id = "Latin-ASCII")
}
#' Remove accent and special characters from a string
#'
#' Remove all accents ans special characters from a text
#'
#' This function calls \code{\link{clean_special_characters}} and \code{\link{clean_accent}}
#' internally
#'
#' @param x Text to be cleared
#' @param replacement a replacement for matched pattern in gsub
#' @seealso See
#'    \code{\link{clean_accent}}
#'    \code{\link{clean_special_characters}}
#'
#' @examples
#' clean_text("JoÃ£o CanÃ¡rio")
#' clean_text("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_text <- function(x, replacement = ""){
x <- clean_special_characters(x, replacement)
x <- clean_accent(x)
x <- gsub("  +", " ", x)
x <- stringi::stri_trans_tolower(x)
stringi::stri_trim_both(x)
}
#' Remove all HTML tags
#'
#' Remove all HTML Tags from a string.
#'
#' @param x Text to be cleared
#'
#' @examples
#' remove_html("<div>Hello, world</div>")
#' remove_html("<div>Hi, I have one <a href='http://link.com'>link here</a>!</div>")
#' remove_html('My text has <mv tipo="url" texto="tag mv" url="2121">tag mv</mv> inside!')
#'
#' @return chr
#'
#'
#' @export
remove_html <- function(x){
gsub(pattern = "<[^>]*>", replacement = "", x, ignore.case = TRUE)
}
library(tm)
library(SnowballC)
getCorpus <- function (field, lower = TRUE, punctuation = TRUE, stopword = TRUE, stem = TRUE){
corpus <- Corpus(VectorSource(field))
if(lower){
corpus = tm_map(corpus, tolower)
#corpus = tm_map(corpus, PlainTextDocument)
}
if(punctuation)
corpus = tm_map(corpus, removePunctuation)
if(stopword)
corpus = tm_map(corpus, removeWords, stopwords("portuguese"))
if(stem)
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removeWords,
c("um", "dois", "tres", "quatro", "cinco", "seis",
"sete", "oito", "nove", "dez"))
corpus
}
##############################
db_schema <- odbcDriverConnect("Driver={SQL Server};Server=tcp:iccserver.database.windows.net,1433;Database=ICC;uid=icc;pwd=Esx@12345678;")
ote <- "8."
ambiente <- "icc"
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s%')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query_formatted <- sprintf(sql_query, lote)
respostas <- execute_query(sql_query_formatted, ambiente)
sql_query_formatted <- sprintf(sql_query, lote)
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s \%')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s" + "%" + "')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
lote <- "8.%"
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query_formatted <- sprintf(sql_query, lote)
sql_query_formatted
respostas <- execute_query(sql_query_formatted, ambiente)
View(respostas)
library(quanteda)
kwic(respostas$Text, "dúvida")
evidencias <- kwic(respostas$Text, "dúvida")
View(evidencias)
View(evidencias)
View(evidencias)
head(evidencias)
??kwic
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
termos_duvidas <- c("mais", "inform*", "duvida*")
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
View(evidencias)
head(evidencias)
termos_duvidas <- c("alg* mais", "mais alg*", "inform*", "duvida*")
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
head(evidencias)
evidencias$docname
duplicated(evidencias$docname)
evidencias[evidencias$docname > 1]
n_occur <- data.frame(table(evidencias$docname))
evidencias[n_occur$Freq > 1,]
evidencias$docname
n_occur$Freq
evidencias[evidencias$id %in% n_occur$Var1[n_occur$Freq > 1],]
evidencias[evidencias$docname %in% n_occur$Var1[n_occur$Freq > 1],]
evidencias$from
evidencias$pre
evidencias$keyword
evidencias$post
head(evidencias)
evidencias$docname[,*]
evidencias$docname[,]
library(NLP)
library(openNLP)
install.packages("openNLP")
install.packages("http://datacube.wu.ac.at/src/contrib/openNLPmodels.pt_1.5-2.tar.gz", repos=NULL, type="source")
library(NLP)
library(openNLP)
install.packages("rJava")
library(NLP)
library(openNLP)
install.packages("openNLP")
library(NLP)
library(openNLP)
sessionInfo()
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
library(NLP)
library(rJava)
library(NLP)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(NLP)
library(rJava)
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
install.packages("rJava")
install.packages("rJava")
library(NLP)
library(openNLP)
library(NLP)
library(openNLP)
install.packages("rJava")
library(NLP)
library(openNLP)
install.packages("RWeka")
library(NLP)
library(openNLP)
source("clean/get_corpus.R")
source("clean/create_bow.R")
source("model/naive_bayes.R")
source("model/evaluate_model.R")
SPAM_PATH <- "./data/spamassassin/*"
# Read texts
spam_corpus <- get_corpus(SPAM_PATH)
# Holdout - split data and labels
m <- nrow(spam_corpus)
train <- sample(1:m, 0.7*m)
train_corpus <- spam_corpus[train ,]
test_corpus <- spam_corpus[-train ,]
all_labels <- docvars(spam_corpus)$class
train_labels <- all_labels[train]
test_labels <- all_labels[-train]
train_bow <- create_bow(train_corpus)
test_bow <- dfm_select(create_bow(test_corpus), train_bow)
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
data("multishapes", package = "factoextra")
db <- datasetBugId[10:669]
db <- datasetBugId[10:632]
library("dbscan")
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5, weights = .2)
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5, weights = as.double(0.2))
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5)
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
#Realizar um agrupamento
library(data.table)
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
result <- result[order(-V1)]
View(result)
library(dplyr)
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
colunas[!colunas %in% metadados]
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
teste_result <- teste[teste$valor_coluna == 1,]
teste_result_final <- teste_result[teste_result$Cluster != 0, ]
teste_result_final <- teste_result_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
teste_result_final <- teste_result_final[order(-teste_result_final$V1),]
teste_result_final <- teste_result_final[teste_result_final$Cluster != 0, ]
View(teste_result_final)
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
data("multishapes", package = "factoextra")
db <- datasetBugId[10:632]
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5)
# Obter os clusters
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
#Ordenar pela quantidade
result <- result[order(-V1)]
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
resultado_pilot <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
resultado_pilot_job <- resultado_pilot[resultado_pilot$valor_coluna == 1,]
# Obtendo apenas os itens  que estavam em algum Cluster
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$Cluster != 0, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
resultado_pilot_job_final <- resultado_pilot_job_final[resultado_pilot_job_final$Cluster != 0, ]
resultado_pilot_job <- resultado_pilot[resultado_pilot$Cluster != 0,]
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$valor_coluna == 1, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
View(resultado_pilot_job_final)
resultado_pilot_job <- resultado_pilot[resultado_pilot$valor_coluna == 1,]
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$Cluster != 0, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
View(resultado_pilot_job_final)
resultado_pilot_job_final <- resultado_pilot_job_final[resultado_pilot_job_final$Cluster != 0, ]
res.dbopt <- dbscan::optics(db,  eps = 0.30, minPts = 5)
res.dbopt$eps_cl
res.dbopt$xi
?kmeans
res.dbkm <- kmeans(x = db, centers=219)
?dbscan
?dbscan::hdbscan
res.dbdbs <- dbscan::hdbscan(x = db,  minPts = 5)
setwd("E:/Mestrado/ExperimentsPapers/BugAID/CodeR")
# ====
# Leitura de CSV
datasetBugId <- read.csv(file="E:/Mestrado/ExperimentsPapers/BugAID/DataSet/dataset_bugid_original.csv", header=TRUE, sep=",")
# ====
# Retirando os metadados do DataSet
# Meta
db <- datasetBugId[11:ncol(datasetBugId)]
# ============================================================
# Rodando o DBScan
source("model/DbScanClustering.R")
dt_dbScan <- dbScanClustering(db, datasetBugId)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_dbScan <- showResult(dt_dbScan)
write.csv(x = result_dbScan, file="results/resultado-dbscan-original.csv")
# ============================================================
# Rodando o K-Means
source("model/KMeansClustering.R")
dt_kMeans <- kMeansClustering(db, datasetBugId)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_kMeans <- showResult(dt_kMeans)
write.csv(x = result_kMeans, file="results/resultado-kMeans-original.csv")
source("model/OpticsClustering.R")
dt_optics <- opticsClustering(db, datasetBugId)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_optics <- showResult(dt_optics)
#colnames(dt_optics)
write.csv(x = result_optics, file="results/resultado-optics-original.csv")
source("model/HDbScanClustering.R")
dt_hdbscan <- hdbscanClustering(db, datasetBugId)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_hdbscan <- showResult(dt_hdbscan)
write.csv(x = result_hdbscan, file="results/resultado-HDBScan-original.csv")
View(result_hdbscan)
View(result_dbScan)
View(result_kMeans)
View(result_optics)
View(db)
power.prop.test(p1 = .9, p2 = .7,
sig.level = 0.05,
power = 0.8,
alternative = "one.sided")
power.prop.test(p1 = .9, p2 = .85,
sig.level = 0.05,
power = 0.8,
alternative = "one.sided")
? power.prop.test
power.prop.test(n = 50, p1 = .50, p2 = .75)      ## => power = 0.740
