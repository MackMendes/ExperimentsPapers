}else if(ambiente == "poc"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:pocs.database.windows.net,1433;Database=poc-net;Uid=pocs;Pwd=123!@#qweQWE;")
}else if(ambiente == "vda"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:srv-db-genoa-vda-net.database.windows.net,1433;Database=db_genoa_vda_net;Uid=genoaadmin;Pwd=#Genoa@022017;")
}else if(ambiente == "icc"){
con <- odbcDriverConnect("Driver={SQL Server};Server=tcp:iccserver.database.windows.net,1433;Database=ICC;Uid=icc;Pwd=Esx@12345678;")
}else{
con <- odbcDriverConnect("Driver={SQL Server};Server=DESKTOP-V9ITFHP\\SQLEXPRESS;Database=POC;Integrated Security=True;Integrated Security=SSPI;")
}
con
}
close_connection <- function(con){
RODBC::odbcClose(con)
}
add_df_to_sql <- function(data, table_name, ambiente){
con <- get_connection(ambiente)
RODBC::sqlSave(con, data, table_name, rownames = FALSE, colnames = FALSE, fast = TRUE, append = TRUE)
close_connection(con)
}
execute_query <- function(query, ambiente){
con <- get_connection(ambiente)
x <- RODBC::sqlQuery(con, query, as.is = TRUE)
RODBC::odbcClose(con)
x
}
#' Clean Special Characters
#'
#' Remove all non-alphanumeric charactes
#'
#' @param x Text to be cleared
#' @param replacement a replacement for matched pattern in gsub
#' @seealso See
#'    \code{\link{clean_text}}
#'    \code{\link{clean_accent}}
#'
#' @examples
#' clean_special_characters("JoÃ£o CanÃ¡rio")
#' clean_special_characters("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_special_characters <- function(x, replacement = ""){
gsub("[^[:alnum:][:blank:]]|[[:punct:]]", replacement, x)
}
#' Clean accents
#'
#' Remove all accents from a text
#'
#' @param x Text to be cleared
#'
#' @seealso See
#'    \code{\link{clean_text}}
#'    \code{\link{clean_special_characters}}
#'    \code{\link[stringi]{stri_trans_general}}
#'
#' @examples
#' clean_accent("JoÃ£o CanÃ¡rio")
#' clean_accent("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_accent <- function(x){
stringi::stri_trans_general(str = x, id = "Latin-ASCII")
}
#' Remove accent and special characters from a string
#'
#' Remove all accents ans special characters from a text
#'
#' This function calls \code{\link{clean_special_characters}} and \code{\link{clean_accent}}
#' internally
#'
#' @param x Text to be cleared
#' @param replacement a replacement for matched pattern in gsub
#' @seealso See
#'    \code{\link{clean_accent}}
#'    \code{\link{clean_special_characters}}
#'
#' @examples
#' clean_text("JoÃ£o CanÃ¡rio")
#' clean_text("OlÃ¡, talvez eu nÃ£o possa ir! Entedeu?")
#'
#' @return chr
#'
#' @export
clean_text <- function(x, replacement = ""){
x <- clean_special_characters(x, replacement)
x <- clean_accent(x)
x <- gsub("  +", " ", x)
x <- stringi::stri_trans_tolower(x)
stringi::stri_trim_both(x)
}
#' Remove all HTML tags
#'
#' Remove all HTML Tags from a string.
#'
#' @param x Text to be cleared
#'
#' @examples
#' remove_html("<div>Hello, world</div>")
#' remove_html("<div>Hi, I have one <a href='http://link.com'>link here</a>!</div>")
#' remove_html('My text has <mv tipo="url" texto="tag mv" url="2121">tag mv</mv> inside!')
#'
#' @return chr
#'
#'
#' @export
remove_html <- function(x){
gsub(pattern = "<[^>]*>", replacement = "", x, ignore.case = TRUE)
}
library(tm)
library(SnowballC)
getCorpus <- function (field, lower = TRUE, punctuation = TRUE, stopword = TRUE, stem = TRUE){
corpus <- Corpus(VectorSource(field))
if(lower){
corpus = tm_map(corpus, tolower)
#corpus = tm_map(corpus, PlainTextDocument)
}
if(punctuation)
corpus = tm_map(corpus, removePunctuation)
if(stopword)
corpus = tm_map(corpus, removeWords, stopwords("portuguese"))
if(stem)
corpus = tm_map(corpus, stemDocument)
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, removeWords,
c("um", "dois", "tres", "quatro", "cinco", "seis",
"sete", "oito", "nove", "dez"))
corpus
}
##############################
db_schema <- odbcDriverConnect("Driver={SQL Server};Server=tcp:iccserver.database.windows.net,1433;Database=ICC;uid=icc;pwd=Esx@12345678;")
ote <- "8."
ambiente <- "icc"
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s%')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query_formatted <- sprintf(sql_query, lote)
respostas <- execute_query(sql_query_formatted, ambiente)
sql_query_formatted <- sprintf(sql_query, lote)
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s \%')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s" + "%" + "')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
lote <- "8.%"
sql_query <- "SELECT tb.[Reference], tb.[ChamadoId], tb.[AudioLength],
LEN(tb.[Text]) AS [LengthText], tb.[Text]
FROM (SELECT DISTINCT chmad.Id AS ChamadoId, ttE.Reference, tfE.AudioLength,
STUFF((SELECT '   ' + ttI.[Text] AS \"text()\" FROM [dbo].[TranscriptionTexts] ttI
INNER JOIN [dbo].[TranscriptionFiles] AS tf ON ttI.[Reference] = tf.[Reference]
WHERE ((tf.AudioLength / 2) <= (ttI.[StartMS] / 1000)  OR  tf.AudioLength < 45)
AND ttE.Reference = ttI.Reference FOR XML PATH('')),1,3, '') AS [Text]
FROM [dbo].[TranscriptionTexts] AS ttE
INNER JOIN [dbo].[Chamados] AS chmad
ON ttE.Reference = chmad.TranscriptionReference
INNER JOIN [dbo].[TranscriptionFiles] AS tfE
ON ttE.[Reference] = tfE.[Reference]
WHERE chmad.duvida_cliente = 1 AND (chmad.Lote LIKE '%s')
AND chmad.[Duvida_Result_ML] > 0.5
GROUP BY ttE.Reference, chmad.Id,  tfE.AudioLength) AS tb
WHERE tb.[Text] IS NOT NULL; "
sql_query_formatted <- sprintf(sql_query, lote)
sql_query_formatted
respostas <- execute_query(sql_query_formatted, ambiente)
View(respostas)
library(quanteda)
kwic(respostas$Text, "dúvida")
evidencias <- kwic(respostas$Text, "dúvida")
View(evidencias)
View(evidencias)
View(evidencias)
head(evidencias)
??kwic
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
termos_duvidas <- c("mais", "inform*", "duvida*")
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
View(evidencias)
head(evidencias)
termos_duvidas <- c("alg* mais", "mais alg*", "inform*", "duvida*")
evidencias <- kwic(respostas$Text, termos_duvidas, window = 3, valuetype = "glob")
head(evidencias)
evidencias$docname
duplicated(evidencias$docname)
evidencias[evidencias$docname > 1]
n_occur <- data.frame(table(evidencias$docname))
evidencias[n_occur$Freq > 1,]
evidencias$docname
n_occur$Freq
evidencias[evidencias$id %in% n_occur$Var1[n_occur$Freq > 1],]
evidencias[evidencias$docname %in% n_occur$Var1[n_occur$Freq > 1],]
evidencias$from
evidencias$pre
evidencias$keyword
evidencias$post
head(evidencias)
evidencias$docname[,*]
evidencias$docname[,]
library(NLP)
library(openNLP)
install.packages("openNLP")
install.packages("http://datacube.wu.ac.at/src/contrib/openNLPmodels.pt_1.5-2.tar.gz", repos=NULL, type="source")
library(NLP)
library(openNLP)
install.packages("rJava")
library(NLP)
library(openNLP)
install.packages("openNLP")
library(NLP)
library(openNLP)
sessionInfo()
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
library(NLP)
library(rJava)
library(NLP)
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(NLP)
library(rJava)
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7')
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7')
library(NLP)
library(openNLP)
install.packages("rJava")
install.packages("rJava")
library(NLP)
library(openNLP)
library(NLP)
library(openNLP)
install.packages("rJava")
library(NLP)
library(openNLP)
install.packages("RWeka")
library(NLP)
library(openNLP)
source("clean/get_corpus.R")
source("clean/create_bow.R")
source("model/naive_bayes.R")
source("model/evaluate_model.R")
SPAM_PATH <- "./data/spamassassin/*"
# Read texts
spam_corpus <- get_corpus(SPAM_PATH)
# Holdout - split data and labels
m <- nrow(spam_corpus)
train <- sample(1:m, 0.7*m)
train_corpus <- spam_corpus[train ,]
test_corpus <- spam_corpus[-train ,]
all_labels <- docvars(spam_corpus)$class
train_labels <- all_labels[train]
test_labels <- all_labels[-train]
train_bow <- create_bow(train_corpus)
test_bow <- dfm_select(create_bow(test_corpus), train_bow)
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
data("multishapes", package = "factoextra")
db <- datasetBugId[10:669]
db <- datasetBugId[10:632]
library("dbscan")
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5, weights = .2)
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5, weights = as.double(0.2))
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5)
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
#Realizar um agrupamento
library(data.table)
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
result <- result[order(-V1)]
View(result)
library(dplyr)
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
colunas[!colunas %in% metadados]
teste <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
teste_result <- teste[teste$valor_coluna == 1,]
teste_result_final <- teste_result[teste_result$Cluster != 0, ]
teste_result_final <- teste_result_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
teste_result_final <- teste_result_final[order(-teste_result_final$V1),]
teste_result_final <- teste_result_final[teste_result_final$Cluster != 0, ]
View(teste_result_final)
datasetBugId <- read.csv(file="E:/Mestrado/Experimentos/DataSet/dataset_bugid_original_with_header.csv", header=TRUE, sep=",")
data("multishapes", package = "factoextra")
db <- datasetBugId[10:632]
res.db <- dbscan::dbscan(db,  eps = 0.30, minPts = 5)
# Obter os clusters
datasetBugId$Cluster <- res.db$cluster
datasetBugId$Qtd = 1;
dt <- data.table(datasetBugId)
result <- dt[, sum(Qtd), by = Cluster]
result <- dt %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
#Ordenar pela quantidade
result <- result[order(-V1)]
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
resultado_pilot <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
resultado_pilot_job <- resultado_pilot[resultado_pilot$valor_coluna == 1,]
# Obtendo apenas os itens  que estavam em algum Cluster
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$Cluster != 0, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
resultado_pilot_job_final <- resultado_pilot_job_final[resultado_pilot_job_final$Cluster != 0, ]
resultado_pilot_job <- resultado_pilot[resultado_pilot$Cluster != 0,]
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$valor_coluna == 1, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
View(resultado_pilot_job_final)
resultado_pilot_job <- resultado_pilot[resultado_pilot$valor_coluna == 1,]
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$Cluster != 0, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>% group_by(Cluster, nome_coluna) %>% summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
View(resultado_pilot_job_final)
resultado_pilot_job_final <- resultado_pilot_job_final[resultado_pilot_job_final$Cluster != 0, ]
res.dbopt <- dbscan::optics(db,  eps = 0.30, minPts = 5)
res.dbopt$eps_cl
res.dbopt$xi
?kmeans
res.dbkm <- kmeans(x = db, centers=219)
?dbscan
?dbscan::hdbscan
res.dbdbs <- dbscan::hdbscan(x = db,  minPts = 5)
# ====
# Leitura de CSV
datasetBugId <- read.csv(file="E:/Mestrado/ExperimentsPapers/BugAID/DataSet/dataset_bugid_original.csv", header=TRUE, sep=",")
nrow(datasetBugId)
crow(datasetBugId)
ncol(datasetBugId)
View(datasetBugId)
db <- datasetBugId[9:ncol(datasetBugId)]
View(db)
db <- datasetBugId[10:ncol(datasetBugId)]
source("model/DbScanClustering.R")
dt_dbScan <- dbScanClustering(db)
setwd("E:/Mestrado/ExperimentsPapers/BugAID/CodeR")
source("model/DbScanClustering.R")
dt_dbScan <- dbScanClustering(db)
?gdub
?gsub
dt <- dt_dbScan
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
library(tidyr)
# Montando estrutura para comparação dos valores
metadados <- c("ID", "ProjectID", "CommitURL", "BuggyCommitID", "BugFixingCommit",
"RepairedCommitID", "Class", "Method", "ModifiedStatementCount",
"Cluster", "Qtd")
colunas <- colnames(dt)
resultado_pilot <- tidyr::gather(dt, "nome_coluna", "valor_coluna", colunas[!colunas %in% metadados])
# Obtendo apenas as linhas com item da Bag-of-Works
resultado_pilot_job <- resultado_pilot[resultado_pilot$valor_coluna == 1,]
# Obtendo apenas os itens  que estavam em algum Cluster
resultado_pilot_job_final <- resultado_pilot_job[resultado_pilot_job$Cluster != 0, ]
resultado_pilot_job_final <- resultado_pilot_job_final %>%
group_by(Cluster, nome_coluna) %>%
summarise(V1 = sum(Qtd))
resultado_pilot_job_final <- resultado_pilot_job_final[order(-resultado_pilot_job_final$V1),]
resultado_aggregate <- aggregate(nome_coluna ~ Cluster, data = resultado_pilot_job_final, c)
resultado_select <- distinct(select(resultado_pilot_job_final, Cluster, V1))
resultado_final <- resultado_aggregate %>% inner_join(resultado_select)
resultado_final$nome_coluna <- as.character(resultado_final$nome_coluna)
View(resultado_final)
txt <- c("arm","foot","lefroo", "bafoobar")
if(length(i <- grep("foo", txt)))
cat("'foo' appears at least once in\n\t", txt, "\n")
i # 2 and 4
txt[i]
gsub("([ab])", "\\1_\\1_", "abc and ABC")
gsub("c(", "", resultado_final$nome_coluna, fixed = TRUE)
gsub(c("c(", "\""), "", resultado_final$nome_coluna, fixed = TRUE)
gsub(c("c(", "\""), c("", ""), resultado_final$nome_coluna, fixed = TRUE)
gsub("c(", "", resultado_final$nome_coluna, fixed = TRUE)
gsub("\"", "", resultado_final$nome_coluna, fixed = TRUE)
resultado_final$nome_coluna <- gsub("c(", "", resultado_final$nome_coluna, fixed = TRUE)
resultado_final$nome_coluna <- gsub("\"", "", resultado_final$nome_coluna, fixed = TRUE)
resultado_final$nome_coluna <- gsub(",", ";", resultado_final$nome_coluna, fixed = TRUE)
View(resultado_final)
resultado_final$nome_coluna <- gsub(")", "", resultado_final$nome_coluna, fixed = TRUE)
?order_by
??order_by
order_by(3, resultado_final)
order_by("v1", resultado_final)
resultado_final[order(v1),]
resultado_final[order(V1),]
resultado_final[order("V1"),]
resultado_final[,order("V1")]
resultado_final[order(resultado_final$V1,)]
resultado_final[order(resultado_final$V1),]
resultado_final[-order(resultado_final$V1),]
resultado_final[order(-resultado_final$V1),]
resultado_final <- resultado_final[order(-resultado_final$V1),]
View(resultado_final)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_dbScan <- showResult(dt_dbScan)
View(db)
db <- datasetBugId[11:ncol(datasetBugId)]
dt_dbScan <- dbScanClustering(db)
result_dbScan <- showResult(dt_dbScan)
View(result_dbScan)
# ====
# Leitura de CSV
datasetBugId <- read.csv(file="E:/Mestrado/ExperimentsPapers/BugAID/DataSet/dataset_bugid_original.csv", header=TRUE, sep=",")
# ====
# Retirando os metadados do DataSet
# Meta
db <- datasetBugId[11:ncol(datasetBugId)]
source("model/DbScanClustering.R")
dt_dbScan <- dbScanClustering(db)
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_dbScan <- showResult(dt_dbScan)
write.csv(x = result_dbScan, file="results/resultado-dbscan-original.csv")
source("model/KMeansClustering.R")
dt_kMeans <- kMeansClustering(db)
# ====
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_kMeans <- showResult(dt_kMeans)
write.csv(x = result_kMeans, file="results/resultado-kMeans-original.csv")
source("model/OpticsClustering.R")
dt_optics <- opticsClustering(db)
# ====
# Montando estrutura para comparação dos valores
source("util/ShowResult.R")
result_optics <- showResult(dt_optics)
#colnames(dt_optics)
write.csv(x = result_optics, file="results/resultado-optics-original.csv")
# Rodando o HDBScan
res.dbdbs <- dbscan::hdbscan(x = db,  minPts = 5)
res.dbdbs <- dbscan::hdbscan(x = db,  minPts = 5)
dbdbs <- dbscan::hdbscan(x = db,  minPts = 5)
result_HDBScan <- showResult(dbdbs)
?hdbscan
source('E:/Mestrado/ExperimentsPapers/BugAID/CodeR/main.R')
datasetBugId$Cluster <- dbdbs$cluster
datasetBugId$Qtd = 1;
library(data.table)
result_HDBScan <- data.table(datasetBugId)
result_HDBScan_fim <- showResult(result_HDBScan)
write.csv(x = result_HDBScan_fim, file="results/resultado-HDBScan-original.csv")
View(result_HDBScan_fim)
View(result_optics)
View(result_kMeans)
View(result_dbScan)
View(result_dbScan)
View(result_dbScan)
View(result_kMeans)
View(result_kMeans)
View(result_optics)
View(result_kMeans)
View(result_optics)
View(result_HDBScan_fim)
View(result_HDBScan_fim)
View(result_optics)
View(result_dbScan)
View(result_HDBScan_fim)
View(result_HDBScan_fim)
View(result_HDBScan)
